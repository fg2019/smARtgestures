{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib.layers.python.layers.layers import convolution\n",
    "from tensorflow.python.ops.nn_impl import relu_layer\n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "import dataImporter\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_count = 10\n",
    "batch_size = 32\n",
    "neurons_fc = 32\n",
    "conv_filter_size = 5\n",
    "feature_maps_layer1 = 16\n",
    "feature_maps_layer2 = 32\n",
    "output_vector_size = 4\n",
    "learn_rate = 1e-4\n",
    "eval_data_amount = 600\n",
    "\n",
    "gesture_data_dir = '../../gestureData' \n",
    "\n",
    "#Variables\n",
    "#source http://cs231n.github.io/neural-networks-2/\n",
    "bias_init_factor = 0.1\n",
    "#random_initializer = tf.contrib.layers.xavier_initializer_conv2d(uniform=True, seed=None, dtype=tf.float32\n",
    "random_initializer = tf.truncated_normal_initializer(stddev=0.1, dtype=tf.float32)\n",
    "#random_initializer = tf.zeros_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3d(x, W):\n",
    "    return tf.nn.conv3d(x, W, strides=[1, 1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool3d(x, ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1], padding='SAME')\n",
    "\n",
    "with tf.name_scope('input'):\n",
    "    input_data = tf.placeholder(tf.float32, shape=[None,40,40,40], name='input_data')\n",
    "    \n",
    "\n",
    "# First \"Layer Stack\"\n",
    "with tf.name_scope('conv_layer_1'):\n",
    "    filters_layer1 = tf.get_variable(\"filter1_variables\",\n",
    "                                     [conv_filter_size, \n",
    "                                      conv_filter_size, conv_filter_size,\n",
    "                                      1,\n",
    "                                      feature_maps_layer1],\n",
    "                                     initializer = random_initializer)\n",
    "    bias_layer1 = tf.get_variable(\"bias1_variables\",\n",
    "                                  [feature_maps_layer1],\n",
    "                                  initializer = tf.constant_initializer(bias_init_factor))\n",
    "    reshapted_input_data = tf.reshape(input_data, [-1, 40, 40, 40, 1])\n",
    "    convolution_layer1 = conv3d(reshapted_input_data, filters_layer1) + bias_layer1\n",
    "\n",
    "with tf.name_scope('pooling_layer_1'):\n",
    "    pooling_layer1 = max_pool_2x2(convolution_layer1)\n",
    "\n",
    "\n",
    "with tf.name_scope('ReLU_layer_1'):\n",
    "    relu_layer1 = tf.nn.relu(pooling_layer1)\n",
    "    \n",
    "\n",
    "    \n",
    "# Second \"Layer Stack\"\n",
    "with tf.name_scope('conv_layer_2'):\n",
    "    filters_layer2 = tf.get_variable(\"filter2_variables\",\n",
    "                                     [conv_filter_size,\n",
    "                                      conv_filter_size,\n",
    "                                      conv_filter_size,\n",
    "                                      feature_maps_layer1,\n",
    "                                      feature_maps_layer2],\n",
    "                                     initializer = random_initializer)\n",
    "    bias_layer2 = tf.get_variable(\"bias2_variables\",\n",
    "                                  [feature_maps_layer2],\n",
    "                                  initializer = tf.constant_initializer(bias_init_factor))    \n",
    "    convolution_layer2 = conv3d(relu_layer1, filters_layer2) + bias_layer2\n",
    "    \n",
    "with tf.name_scope('pooling_layer_2'):\n",
    "    pooling_layer2 = max_pool_2x2(convolution_layer2)\n",
    "\n",
    "with tf.name_scope('ReLU_layer_2'):\n",
    "    relu_layer2 = tf.nn.relu(pooling_layer2)\n",
    "\n",
    "    \n",
    "# Start Fully connected layers    \n",
    "with tf.name_scope('fc_layer_1'):\n",
    "    weights_fc1 = tf.get_variable(\"fc1_variables\",\n",
    "                            [10 * 10 * 10 * feature_maps_layer2, neurons_fc],\n",
    "                            initializer = random_initializer)\n",
    "    bias_fc1 = tf.get_variable(\"bias_fc1_variables\",\n",
    "                               [neurons_fc],\n",
    "                               initializer = tf.constant_initializer(bias_init_factor))\n",
    "\n",
    "    pool_layer2_flat = tf.reshape(relu_layer2, [-1, 10 * 10 * 10*feature_maps_layer2])\n",
    "    fc1 = tf.nn.relu(tf.matmul(pool_layer2_flat, weights_fc1) + bias_fc1)\n",
    "    \n",
    "with tf.name_scope('dropout_layer'):\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    fc1_dropout = tf.nn.dropout(fc1, keep_prob)\n",
    "\n",
    "with tf.name_scope('fc_layer_2'):\n",
    "    weights_fc2 = tf.get_variable(\"fc2_variables\",\n",
    "                                  [neurons_fc, output_vector_size],\n",
    "                                  initializer = random_initializer)\n",
    "    bias_fc2 = tf.get_variable(\"bias_fc2_variables\",\n",
    "                               [output_vector_size],\n",
    "                               initializer = tf.constant_initializer(bias_init_factor))\n",
    "    \n",
    "    output_class_probabilities = tf.matmul(fc1_dropout, weights_fc2) + bias_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-0ed79f6eb9b8>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "desired_label = tf.placeholder(tf.float32, shape=[None,4], name='desired_label')\n",
    "\n",
    "with tf.name_scope('error'):\n",
    "    error = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=desired_label, logits=output_class_probabilities))\n",
    "\n",
    "with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.AdamOptimizer(learn_rate)\n",
    "    train_step = optimizer.minimize(error)\n",
    "        \n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(output_class_probabilities, 1), tf.argmax(desired_label, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported data of 50 gestures\n",
      "starting to cleanup gesture Data...\n",
      "done cleaning up. Removed 2 gestures\n",
      "starting to close gaps in gesture coordinate data...\n",
      "done closing gaps... Added 1001 coordinates\n",
      "augumented input data 384\n",
      "starting to transpose 384 discrete gestures\n",
      "having 768 gestures now\n",
      "starting to flip 768 discrete gestures on axis 0\n",
      "having 1536 gestures now\n",
      "starting to flip 1536 discrete gestures on axis 1\n",
      "having 3072 gestures now\n",
      "starting to flip 3072 discrete gestures on axis 2\n",
      "having 6144 gestures now\n",
      "starting to shift 6144 gestures\n",
      "having 12288 now\n",
      "starting to shift down 12288 gestures\n",
      "having 24576 now\n",
      "starting to shift back 24576 gestures\n",
      "having 49152 now\n",
      " \n",
      "compressing...\n",
      "imported data of 50 gestures\n",
      "starting to cleanup gesture Data...\n",
      "done cleaning up. Removed 0 gestures\n",
      "starting to close gaps in gesture coordinate data...\n",
      "done closing gaps... Added 188 coordinates\n",
      "augumented input data 400\n",
      "starting to transpose 400 discrete gestures\n",
      "having 800 gestures now\n",
      "starting to flip 800 discrete gestures on axis 0\n",
      "having 1600 gestures now\n",
      "starting to flip 1600 discrete gestures on axis 1\n",
      "having 3200 gestures now\n",
      "starting to flip 3200 discrete gestures on axis 2\n",
      "having 6400 gestures now\n",
      "starting to shift 6400 gestures\n",
      "having 12800 now\n",
      "starting to shift down 12800 gestures\n",
      "having 25600 now\n",
      "starting to shift back 25600 gestures\n",
      "having 51200 now\n",
      " \n",
      "compressing...\n",
      "imported data of 50 gestures\n",
      "starting to cleanup gesture Data...\n",
      "done cleaning up. Removed 1 gestures\n",
      "starting to close gaps in gesture coordinate data...\n",
      "done closing gaps... Added 193 coordinates\n",
      "augumented input data 392\n",
      "starting to transpose 392 discrete gestures\n",
      "having 784 gestures now\n",
      "starting to flip 784 discrete gestures on axis 0\n",
      "having 1568 gestures now\n",
      "starting to flip 1568 discrete gestures on axis 1\n",
      "having 3136 gestures now\n",
      "starting to flip 3136 discrete gestures on axis 2\n",
      "having 6272 gestures now\n",
      "starting to shift 6272 gestures\n",
      "having 12544 now\n",
      "starting to shift down 12544 gestures\n",
      "having 25088 now\n",
      "starting to shift back 25088 gestures\n",
      "having 50176 now\n",
      " \n",
      "compressing...\n",
      "imported data of 50 gestures\n",
      "starting to cleanup gesture Data...\n",
      "done cleaning up. Removed 1 gestures\n",
      "starting to close gaps in gesture coordinate data...\n",
      "done closing gaps... Added 1062 coordinates\n",
      "augumented input data 392\n",
      "starting to transpose 392 discrete gestures\n",
      "having 784 gestures now\n",
      "starting to flip 784 discrete gestures on axis 0\n",
      "having 1568 gestures now\n",
      "starting to flip 1568 discrete gestures on axis 1\n",
      "having 3136 gestures now\n",
      "starting to flip 3136 discrete gestures on axis 2\n",
      "having 6272 gestures now\n",
      "starting to shift 6272 gestures\n",
      "having 12544 now\n",
      "starting to shift down 12544 gestures\n",
      "having 25088 now\n",
      "starting to shift back 25088 gestures\n",
      "having 50176 now\n",
      " \n",
      "compressing...\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data + dataImporter.get_discrete3D_data(dataImporter.read_data_from_file(gesture_data_dir + \"/circle/trainData.json\"), True, True)\n",
    "train_data = train_data + dataImporter.get_discrete3D_data(dataImporter.read_data_from_file(gesture_data_dir + \"/v/trainData.json\"), True, True)\n",
    "train_data = train_data + dataImporter.get_discrete3D_data(dataImporter.read_data_from_file(gesture_data_dir + \"/circle/trainData2.json\"), True, True)\n",
    "train_data = train_data + dataImporter.get_discrete3D_data(dataImporter.read_data_from_file(gesture_data_dir + \"/line/trainData.json\"), True, True)\n",
    "train_data = train_data + dataImporter.get_discrete3D_data(dataImporter.read_data_from_file(gesture_data_dir + \"/line/trainData2.json\"), True, True)\n",
    "train_data = train_data + dataImporter.get_discrete3D_data(dataImporter.read_data_from_file(gesture_data_dir + \"/v/trainData2.json\"), True, True)\n",
    "train_data = train_data + dataImporter.get_discrete3D_data(dataImporter.read_data_from_file(gesture_data_dir + \"/wave/trainData.json\"), True, True)\n",
    "train_data = train_data + dataImporter.get_discrete3D_data(dataImporter.read_data_from_file(gesture_data_dir + \"/wave/trainData2.json\"), True, True)\n",
    "shuffle(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_data = []\n",
    "#ensure random eval data is equally distributed through all gesture types!\n",
    "eval_data_class_counts = {0:0,1:0,2:0,3:0}\n",
    "while len(eval_data) < eval_data_amount:\n",
    "    element = train_data.pop()\n",
    "    element_class_id = np.array(element[1]).nonzero()[0][0]\n",
    "    if eval_data_class_counts[element_class_id]<int(eval_data_amount/4):\n",
    "        eval_data_class_counts[element_class_id] = eval_data_class_counts[element_class_id] + 1\n",
    "        eval_data.append(element)\n",
    "    else:\n",
    "        train_data.insert(0,element)\n",
    "    \n",
    "decompressed_batch = dataImporter.decompress_3D(eval_data)\n",
    "eval_input_batch = []\n",
    "eval_label_batch = []\n",
    "for j in range(eval_data_amount):\n",
    "    eval_input_batch.append(decompressed_batch[j][0])\n",
    "    eval_label_batch.append(decompressed_batch[j][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported data of 50 gestures\n",
      "starting to cleanup gesture Data...\n",
      "done cleaning up. Removed 1 gestures\n",
      "starting to close gaps in gesture coordinate data...\n",
      "done closing gaps... Added 193 coordinates\n",
      " \n",
      "compressing...\n",
      "imported data of 50 gestures\n",
      "starting to cleanup gesture Data...\n",
      "done cleaning up. Removed 0 gestures\n",
      "starting to close gaps in gesture coordinate data...\n",
      "done closing gaps... Added 875 coordinates\n",
      " \n",
      "compressing...\n",
      "imported data of 50 gestures\n",
      "starting to cleanup gesture Data...\n",
      "done cleaning up. Removed 0 gestures\n",
      "starting to close gaps in gesture coordinate data...\n",
      "done closing gaps... Added 370 coordinates\n",
      " \n",
      "compressing...\n",
      "imported data of 50 gestures\n",
      "starting to cleanup gesture Data...\n",
      "done cleaning up. Removed 0 gestures\n",
      "starting to close gaps in gesture coordinate data...\n",
      "done closing gaps... Added 875 coordinates\n",
      " \n",
      "compressing...\n",
      "its 199 testdata\n"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "test_data = dataImporter.get_discrete3D_data(dataImporter.read_data_from_file(gesture_data_dir + \"/line/testData.json\"), True, False)\n",
    "test_data = test_data + dataImporter.get_discrete3D_data(dataImporter.read_data_from_file(gesture_data_dir + \"/circle/testData.json\"), True, False)\n",
    "test_data = test_data + dataImporter.get_discrete3D_data(dataImporter.read_data_from_file(gesture_data_dir + \"/v/testData.json\"), True, False)\n",
    "test_data = test_data + dataImporter.get_discrete3D_data(dataImporter.read_data_from_file(gesture_data_dir + \"/wave/testData.json\"), True, False)\n",
    "test_data_count = len(test_data)\n",
    "shuffle(test_data)\n",
    "print(\"its \" + repr(test_data_count) + \" testdata\")\n",
    "\n",
    "decompressed_batch = dataImporter.decompress_3D(test_data)\n",
    "test_input_batch = []\n",
    "test_label_batch = []\n",
    "for j in range(test_data_count):\n",
    "    test_input_batch.append(decompressed_batch[j][0])\n",
    "    test_label_batch.append(decompressed_batch[j][1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported data of 43 gestures\n",
      "starting to cleanup gesture Data...\n",
      "done cleaning up. Removed 1 gestures\n",
      "starting to close gaps in gesture coordinate data...\n",
      "done closing gaps... Added 628 coordinates\n",
      " \n",
      "compressing...\n",
      "imported data of 37 gestures\n",
      "starting to cleanup gesture Data...\n",
      "done cleaning up. Removed 1 gestures\n",
      "starting to close gaps in gesture coordinate data...\n",
      "done closing gaps... Added 1237 coordinates\n",
      " \n",
      "compressing...\n",
      "imported data of 36 gestures\n",
      "starting to cleanup gesture Data...\n",
      "done cleaning up. Removed 3 gestures\n",
      "starting to close gaps in gesture coordinate data...\n",
      "done closing gaps... Added 1548 coordinates\n",
      " \n",
      "compressing...\n",
      "imported data of 43 gestures\n",
      "starting to cleanup gesture Data...\n",
      "done cleaning up. Removed 1 gestures\n",
      "starting to close gaps in gesture coordinate data...\n",
      "done closing gaps... Added 1287 coordinates\n",
      " \n",
      "compressing...\n",
      "imported data of 36 gestures\n",
      "starting to cleanup gesture Data...\n",
      "done cleaning up. Removed 4 gestures\n",
      "starting to close gaps in gesture coordinate data...\n",
      "done closing gaps... Added 529 coordinates\n",
      " \n",
      "compressing...\n",
      "its 185 fremdgesten\n"
     ]
    }
   ],
   "source": [
    "fremdgesten_data = []\n",
    "fremdgesten_data = dataImporter.get_discrete3D_data(dataImporter.read_data_from_file(gesture_data_dir + \"/fremdGestendaten/person1.json\"), True, False)\n",
    "fremdgesten_data = fremdgesten_data + dataImporter.get_discrete3D_data(dataImporter.read_data_from_file(gesture_data_dir + \"/fremdGestendaten/person2.json\"), True, False)\n",
    "fremdgesten_data = fremdgesten_data + dataImporter.get_discrete3D_data(dataImporter.read_data_from_file(gesture_data_dir + \"/fremdGestendaten/person3.json\"), True, False)\n",
    "fremdgesten_data = fremdgesten_data + dataImporter.get_discrete3D_data(dataImporter.read_data_from_file(gesture_data_dir + \"/fremdGestendaten/person4.json\"), True, False)\n",
    "fremdgesten_data = fremdgesten_data + dataImporter.get_discrete3D_data(dataImporter.read_data_from_file(gesture_data_dir + \"/fremdGestendaten/person5.json\"), True, False)\n",
    "fremdgesten_data_count = len(fremdgesten_data)\n",
    "shuffle(fremdgesten_data)\n",
    "print(\"its \" + repr(fremdgesten_data_count) + \" fremdgesten\")\n",
    "\n",
    "decompressed_batch = dataImporter.decompress_3D(fremdgesten_data)\n",
    "fremdgesten_input_batch = []\n",
    "fremdgesten_label_batch = []\n",
    "for j in range(fremdgesten_data_count):\n",
    "    fremdgesten_input_batch.append(decompressed_batch[j][0])\n",
    "    fremdgesten_label_batch.append(decompressed_batch[j][1])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter('../../tensorboard/tmp', graph=tf.get_default_graph())\n",
    "\n",
    "acuracy_op_eval = tf.summary.scalar(\"accuracy_eval\", accuracy)\n",
    "acuracy_op_test = tf.summary.scalar(\"accuracy_test\", accuracy)\n",
    "acuracy_op_train = tf.summary.scalar(\"accuracy_train\", accuracy)\n",
    "error_op_eval = tf.summary.scalar(\"error_eval\", error)\n",
    "error_op_test = tf.summary.scalar(\"error_test\", error)\n",
    "error_op_train = tf.summary.scalar(\"error_train\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('session'):\n",
    "    session = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./storedSessions/10Each40Epoch/model10Each.ckpt\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to get matching files on ./storedSessions/10Each40Epoch/model10Each.ckpt: Not found: ./storedSessions/10Each40Epoch; No such file or directory\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save_1/RestoreV2', defined at:\n  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-20-563fae52115c>\", line 2, in <module>\n    saver = tf.train.Saver()\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1311, in __init__\n    self.build()\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1320, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1357, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 809, in _build_internal\n    restore_sequentially, reshape)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 448, in _AddRestoreOps\n    restore_sequentially)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 860, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1458, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to get matching files on ./storedSessions/10Each40Epoch/model10Each.ckpt: Not found: ./storedSessions/10Each40Epoch; No such file or directory\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/evonik/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/evonik/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/evonik/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/evonik/tf/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to get matching files on ./storedSessions/10Each40Epoch/model10Each.ckpt: Not found: ./storedSessions/10Each40Epoch; No such file or directory\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-563fae52115c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#restore if there is already a trained model..\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./storedSessions/10Each40Epoch/model10Each.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/evonik/tf/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1775\u001b[0;31m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/evonik/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/evonik/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/evonik/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/evonik/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to get matching files on ./storedSessions/10Each40Epoch/model10Each.ckpt: Not found: ./storedSessions/10Each40Epoch; No such file or directory\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save_1/RestoreV2', defined at:\n  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-20-563fae52115c>\", line 2, in <module>\n    saver = tf.train.Saver()\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1311, in __init__\n    self.build()\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1320, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1357, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 809, in _build_internal\n    restore_sequentially, reshape)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 448, in _AddRestoreOps\n    restore_sequentially)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 860, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1458, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/Users/tobirohrer/evonik/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to get matching files on ./storedSessions/10Each40Epoch/model10Each.ckpt: Not found: ./storedSessions/10Each40Epoch; No such file or directory\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "#restore if there is already a trained model..\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(session, \"./storedSessions/10Each40Epoch/model10Each.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on 200104 gestures\n",
      "evaluating on 600 gestures\n",
      "thats 6253 iterations per epoch\n",
      "...and its 10 epochs, so lean back and wait!\n",
      "\n",
      "starting epoch 0\n",
      "0.255\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-35b22d428fb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mlabel_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecompressed_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_label\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m#monitor training process:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/evonik/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/evonik/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/evonik/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/evonik/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/evonik/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/evonik/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iterations = int(len(train_data)/batch_size)\n",
    "print(\"training on \" + repr(len(train_data)) + \" gestures\")\n",
    "print(\"evaluating on \" + repr(len(eval_data)) + \" gestures\")\n",
    "print(\"thats \" + repr(iterations) + \" iterations per epoch\")\n",
    "print(\"...and its \" + repr(epoch_count) + \" epochs, so lean back and wait!\")\n",
    "\n",
    "with tf.name_scope('training...'):\n",
    "    for e in range(epoch_count):\n",
    "        print(\"\")\n",
    "        print(\"starting epoch \" + repr(e))\n",
    "        shuffle(train_data)\n",
    "        for i in range(iterations):\n",
    "            \n",
    "            compressed_batch = []\n",
    "            for j in range(batch_size):\n",
    "                compressed_batch.append(train_data[i*batch_size+j])\n",
    "            decompressed_batch = dataImporter.decompress_3D(compressed_batch)\n",
    "            input_batch = []\n",
    "            label_batch = []\n",
    "            for j in range(batch_size):\n",
    "                input_batch.append(decompressed_batch[j][0])\n",
    "                label_batch.append(decompressed_batch[j][1])\n",
    "\n",
    "            session.run(train_step,feed_dict={input_data: input_batch, desired_label: label_batch, keep_prob: 0.5})\n",
    "            \n",
    "            #monitor training process:\n",
    "            if(i%500 == 0):\n",
    "                print(session.run(accuracy, feed_dict={input_data: eval_input_batch, desired_label: eval_label_batch, keep_prob: 1.0}))\n",
    "            \n",
    "            if(i%100 == 0):\n",
    "                #tensorboard logging!\n",
    "                train_data_batch = []\n",
    "                for j in range(eval_data_amount):\n",
    "                    train_data_batch.append(train_data[j])\n",
    "                \n",
    "                decompressed_train_batch = dataImporter.decompress_3D(train_data_batch)\n",
    "                train_input_batch = []\n",
    "                train_label_batch = []\n",
    "                for j in range(eval_data_amount):\n",
    "                    train_input_batch.append(decompressed_train_batch[j][0])\n",
    "                    train_label_batch.append(decompressed_train_batch[j][1])\n",
    "\n",
    "                \n",
    "                error_summary_eval = session.run(error_op_eval,feed_dict={input_data: eval_input_batch, desired_label: eval_label_batch, keep_prob:1.0})\n",
    "                error_summary_test = session.run(error_op_test,feed_dict={input_data: test_input_batch, desired_label: test_label_batch, keep_prob:1.0})\n",
    "                error_summary_train = session.run(error_op_train,feed_dict={input_data: train_input_batch, desired_label: train_label_batch, keep_prob:1.0})\n",
    "                \n",
    "                acuracy_summary_eval = session.run(acuracy_op_eval,feed_dict={input_data: eval_input_batch, desired_label: eval_label_batch, keep_prob:1.0})\n",
    "                acuracy_summary_test = session.run(acuracy_op_test,feed_dict={input_data: test_input_batch, desired_label: test_label_batch, keep_prob:1.0})\n",
    "                acuracy_summary_train = session.run(acuracy_op_train,feed_dict={input_data: train_input_batch, desired_label: train_label_batch, keep_prob:1.0})\n",
    "                \n",
    "                writer.add_summary(error_summary_eval, i+((e)*iterations))\n",
    "                writer.add_summary(acuracy_summary_eval, i+((e)*iterations))\n",
    "                writer.add_summary(error_summary_test, i+((e)*iterations))\n",
    "                writer.add_summary(acuracy_summary_test, i+((e)*iterations))\n",
    "                writer.add_summary(error_summary_train, i+((e)*iterations))\n",
    "                writer.add_summary(acuracy_summary_train, i+((e)*iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.flush()\n",
    "writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on testdata:\n",
      "accuracy on evaldata:\n",
      "accuracy on fremdgesten:\n",
      "0.25405404\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy on testdata:\")\n",
    "print(session.run(accuracy,feed_dict={input_data: test_input_batch, desired_label: np.matrix(test_label_batch), keep_prob:1.0}))\n",
    "print(\"accuracy on evaldata:\")\n",
    "print(session.run(accuracy,feed_dict={input_data: eval_input_batch, desired_label: np.matrix(eval_label_batch), keep_prob:1.0}))\n",
    "print(\"accuracy on fremdgesten:\")\n",
    "print(session.run(accuracy,feed_dict={input_data: fremdgesten_input_batch, desired_label: np.matrix(fremdgesten_label_batch), keep_prob:1.0}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation (Draft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-a974ee98b318>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprojection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'3d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mzs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X Label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "xs,ys,zs = np.nonzero(eval_data[1][0])\n",
    "ax.scatter(xs,zs,ys)\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Z Label')\n",
    "ax.set_zlabel('Y Label')\n",
    "plt.show()\n",
    "\n",
    "conv_layer1 = session.run(convolution_layer1, {x: np.matrix(eval_data[1][0].flatten())})\n",
    "transposed_conv_layer1 = tf.transpose(conv_layer1, [4, 1, 2, 3,0])\n",
    "\n",
    "#its now an \"array\" of 3D cubes\n",
    "for i in range(transposed_conv_layer1.shape[0]):\n",
    "    single_feature_map = transposed_conv_layer1[i]\n",
    "    print(i)\n",
    "    #get rid of nonsense last dimension\n",
    "    conv_3d = tf.reshape(single_feature_map, (40,40,40))\n",
    "    #plot\n",
    "    fig= plt.figure(i)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    x1, y1, z1 = np.nonzero(np.around(session.run(conv_3d)))\n",
    "    ax.scatter(x1,z1,y1)\n",
    "    ax.set_xlabel('X Label')\n",
    "    ax.set_ylabel('Z Label')\n",
    "    ax.set_zlabel('Y Label')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-99aa73724296>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mfilter_3d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msingle_filter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mconv_filter_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconv_filter_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconv_filter_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m111\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprojection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'3d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter_3d\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "transposed_filters_layer1 = tf.transpose(filters_layer1, [4, 0, 1, 2, 3])\n",
    "for i in range(transposed_filters_layer1.shape[0]):\n",
    "    single_filter = transposed_filters_layer1[i]\n",
    "    print(i)\n",
    "    #get rid of nonsense last dimension\n",
    "    filter_3d = tf.reshape(single_filter, (conv_filter_size,conv_filter_size,conv_filter_size))\n",
    "    #plot\n",
    "    fig= plt.figure(i)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    x1, y1, z1 = np.nonzero(session.run(filter_3d))\n",
    "    c = session.run(filter_3d).flatten()\n",
    "    #dunkel ist mehr und nicht andersrum\n",
    "    c = c*-1\n",
    "    ax.scatter(x1, y1, z1, c=c, cmap=plt.gray())\n",
    "    ax.set_xlabel('X Label')\n",
    "    ax.set_ylabel('Z Label')\n",
    "    ax.set_zlabel('Y Label')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transposed_filters_layer1 = tf.transpose(filters_layer1, [4, 0, 1, 2, 3])\n",
    "single_filter = transposed_filters_layer1[0]\n",
    "#get rid of nonsense last dimension\n",
    "filter_3d = tf.reshape(single_filter, (conv_filter_size,conv_filter_size,conv_filter_size))\n",
    "#plot\n",
    "fig= plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "x1, y1, z1 = np.nonzero(session.run(filter_3d))\n",
    "c = session.run(filter_3d).flatten()\n",
    "for i in range(len(c)):\n",
    "    if(c[i] < 0.1):\n",
    "        c[i] = 0\n",
    "#dunkel ist mehr und nicht andersrum\n",
    "c = c*-1\n",
    "ax.scatter(x1, z1, y1, c=c, cmap=plt.gray())\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Z Label')\n",
    "ax.set_zlabel('Y Label')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
